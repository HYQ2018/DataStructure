# 海量数据处理
单机处理海量数据的大体主流思想是和MapReduce框架一样，都是采取分而治之的方法，将海量数据切分为若干小份来进行处理，
并且在处理的过程中要兼顾内存的使用情况和处理并发量情况。而更加仔细的处理流程大体上分为几步（对大多数情况都使用，
其中少部分情况要根据你自己的实际情况和其他解决方法做比较采用最符合实际的方法）：

* 第一步：分而治之。
    采用Hash取模进行等价映射。采用这种方法可以将巨大的文件进行等价分割（注意：符合一定规律的数据要被分割到同一个小文件）变成若干个小文件再进行处理。
这个方法针对数据量巨大，内存受到限制时十分有效。

* 第二步：利用hashMap在内存中进行统计。
    我们通过Hash映射将大文件分割为小文件后，就可以采用HashMap这样的存储结构来对小文件中的关注项进行频率统计。
具体的做法是将要进行统计的Item作为HashMap的key，此Item出现的次数作为value。

* 第三步：在上一步进行统计完毕之后根据场景需求往往需要对存储在HashMap中的数据根据出现的次数来进行排序。
其中排序我们可以采用堆排序、快速排序、归并排序等方法。

## TOP N问题
1.如何在海量数据中找到重复最多的TopN个。
* 将每个数据通过hash映射为M个小文件（M是可以处理的数，一般N<M，且hash映射要保证相同的数据映射到相同的文件）。
* 对每个小文件进行hash_map统计，找出每个小文件的重复最多。(共计M个)。
* 对M个数据进行堆排序得到最多的N个。


EX1.1、海量日志数据，提取出某日访问百度次数最多的那个IP
分析：百度作为国内第一大搜索引擎，每天访问它的IP数量巨大，如果想一次性把所有IP数据装进内存处理，则内存容量明显不够，故针对数据太大，内存受限的情况，
可以把大文件转化成（取模映射）小文件，从而大而化小，逐个处理。

* 通过对IP取模进行hash映射将海量IP分割为M个小文件，使得相同的IP落在相同的文件。
* 对每个小文件使用hash_map统计访问最多的IP。最后共得M个数据。
* 对M个数据进行堆排序得到访问最多的IP.
注：Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中去的情况，即这里采用的是%1000算法，那么同一个IP在hash后，
  只可能落在同一个文件中，不可能被分散的。
  
EX2.
搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，请你统计最热门的10个查询串，
要求使用的内存不能超过1G。

CASE1:内存存不下，数据大则划为小的，可先%quer，并保证一种quer只出现在一个文件中，
再对每个小文件中的quer进行hash_map统计并按数量排序，最后归并或者最小堆依次处理每个小文件的top10以得到最后的结果。

CASE2:内存村得下，利用小顶堆求解。先将quer进行hash_map.对哈希表前10个quer建立建立小顶堆(O(log(10)),遍历剩余每个quer,如果该查询的频数大于
      堆顶元素，则替换调堆顶，在调整堆。复杂堆为O(nlog(10))
 
