# 海量数据处理
单机处理海量数据的大体主流思想是和MapReduce框架一样，都是采取分而治之的方法，将海量数据切分为若干小份来进行处理，
并且在处理的过程中要兼顾内存的使用情况和处理并发量情况。而更加仔细的处理流程大体上分为几步（对大多数情况都使用，
其中少部分情况要根据你自己的实际情况和其他解决方法做比较采用最符合实际的方法）：

* 第一步：分而治之。
    采用Hash取模进行等价映射。采用这种方法可以将巨大的文件进行等价分割（注意：符合一定规律的数据要被分割到同一个小文件）变成若干个小文件再进行处理。
这个方法针对数据量巨大，内存受到限制时十分有效。

* 第二步：利用hashMap在内存中进行统计。
    我们通过Hash映射将大文件分割为小文件后，就可以采用HashMap这样的存储结构来对小文件中的关注项进行频率统计。
具体的做法是将要进行统计的Item作为HashMap的key，此Item出现的次数作为value。

* 第三步：在上一步进行统计完毕之后根据场景需求往往需要对存储在HashMap中的数据根据出现的次数来进行排序。
其中排序我们可以采用堆排序、快速排序、归并排序等方法。

## TOP N问题
1.如何在海量数据中找到重复最多的TopN个。
* 将每个数据通过hash映射为M个小文件（M是可以处理的数，一般N<M，且hash映射要保证相同的数据映射到相同的文件）。
* 对每个小文件进行hash_map统计，找出每个小文件的重复最多。(共计M个)。
* 对M个数据进行堆排序得到最多的N个。


EX1.1、海量日志数据，提取出某日访问百度次数最多的那个IP
分析：百度作为国内第一大搜索引擎，每天访问它的IP数量巨大，如果想一次性把所有IP数据装进内存处理，则内存容量明显不够，故针对数据太大，内存受限的情况，
可以把大文件转化成（取模映射）小文件，从而大而化小，逐个处理。

* 通过对IP取模进行hash映射将海量IP分割为M个小文件，使得相同的IP落在相同的文件。
* 对每个小文件使用hash_map统计访问最多的IP。最后共得M个数据。
* 对M个数据进行堆排序得到访问最多的IP.
注：Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中去的情况，即这里采用的是%1000算法，那么同一个IP在hash后，
  只可能落在同一个文件中，不可能被分散的。
  
EX2.
搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，请你统计最热门的10个查询串，
要求使用的内存不能超过1G。

CASE1:内存存不下，数据大则划为小的，可先%quer，并保证一种quer只出现在一个文件中，
再对每个小文件中的quer进行hash_map统计并按数量排序，最后归并或者最小堆依次处理每个小文件的top10以得到最后的结果。

CASE2:内存村得下，利用小顶堆求解。先将quer进行hash_map.对哈希表前10个quer建立建立小顶堆(O(log(10)),遍历剩余每个quer,如果该查询的频数大于
      堆顶元素，则替换调堆顶，在调整堆。复杂堆为O(nlog(10))
 
EX3.
1G的文件，里面1行1个不超过16字节的词。内存限制1M，返回频数最高前100（同2）。
* 将单词 % 5000存入5000小文件平均各文件约200K
* 对超过1M的文件继续分割直到小于200K
* 使用map统计各个词出现的频率
* 对5000词使用堆排序或归并排序


## 分布式TOPN问题
分布在100台电脑的海量数据，统计前十。
* CASE1:如果相同元素只会出现在同一台电脑上，那么同上。分别在每台电脑上hash_map求出top10,再将100台电脑的top10组合起来使用堆排序求top10.
* CASE2:如果相同元素可能出现在不同电脑上，那么必须遍历一遍数据，对每个数据hash映射，使得相同元素出现在同一电脑，再使用CASE1.

## 内存内TOP N问题
EX
100w个数字找出最大100个。
* 利用小顶堆，建立一个100的小顶堆，然后便利数据，比堆顶大则替换掉堆顶元素，然后调整堆。
最后得到的堆就是最大的100个。


## 公共数据问题

A,B两个文件各存放50亿url，每个为64Byte，限制内存4G找出公共url。
* 对A和B两个大文件，先通过url % 1000将数据映射到1000个文件中，单个文件大小约320M（我们只需要检查对应小文件A1 V B1......，不对应小文件不会有相同url）
* 通过hash_set统计，把A1的url存储到hash_set中，再遍历对应的B1小文件，检查是否在hash_set中，若存在则写入外存。重复循环处理对应的1000个对。

